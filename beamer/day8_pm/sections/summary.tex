\section{Summary and Framework Selection}

\subsection{Core Concepts Review}
\begin{frame}[fragile]{\emoji{brain} C++ Concurrency Core Concepts}
	\textbf{The Three Pillars}:

	\begin{tikzpicture}
		% Pillar 1: Thread
		\node[draw, rectangle, fill=blue!20, minimum height=3cm, minimum width=2.5cm] (thread) at (0,0) {};
		\node[font=\bfseries] at (0,1) {\texttt{std::thread}};
		\node[font=\small, align=center] at (0,0) {Thread Creation\\Parameter Passing\\Lifecycle Management};
		\node[font=\small] at (0,-1) {join() / detach()};

		% Pillar 2: Mutex
		\node[draw, rectangle, fill=green!20, minimum height=3cm, minimum width=2.5cm] (mutex) at (4,0) {};
		\node[font=\bfseries] at (4,1) {\texttt{std::mutex}};
		\node[font=\small, align=center] at (4,0) {Mutual Exclusion\\RAII Locking\\Deadlock Prevention};
		\node[font=\small] at (4,-1) {lock\_guard};

		% Pillar 3: Condition Variable
		\node[draw, rectangle, fill=red!20, minimum height=3cm, minimum width=2.5cm] (cv) at (8,0) {};
		\node[font=\bfseries] at (8,1) {\texttt{std::condition\_variable}};
		\node[font=\small, align=center] at (8,0) {Efficient Waiting\\Producer-Consumer\\Event Synchronization};
		\node[font=\small] at (8,-1) {wait() / notify()};
	\end{tikzpicture}

	\vspace{2em}
	\textbf{Best Practices Checklist}:
	\begin{itemize}
		\item \emoji{check-mark} Always join() or detach() threads
		\item \emoji{check-mark} Use RAII locks (\texttt{lock\_guard}, \texttt{unique\_lock})
		\item \emoji{check-mark} Avoid deadlocks with ordered locking
		\item \emoji{check-mark} Use condition variables instead of busy-waiting
		\item \emoji{check-mark} Pass by value or \texttt{std::ref} explicitly
	\end{itemize}
\end{frame}

\subsection{Framework Selection Guide}
\begin{frame}[fragile]{\emoji{compass} When to Choose Which Framework}
	\begin{tikzpicture}[node distance=1.5cm]
		% Decision tree
		\node[draw, diamond, fill=yellow!20] (start) {Parallel Task};

		\node[draw, diamond, below left of=start, fill=blue!10] (pattern) {Regular Pattern?};
		\node[draw, diamond, below right of=start, fill=blue!10] (scale) {Scale Requirement?};

		\node[draw, rectangle, below of=pattern, fill=green!20] (openmp) {OpenMP};
		\node[draw, rectangle, below left of=scale, fill=red!20] (cpp) {C++ Thread};
		\node[draw, rectangle, below right of=scale, fill=purple!20] (mpi) {MPI};

		% Arrows with labels
		\draw[->] (start) -- node[above left] {Data Parallel} (pattern);
		\draw[->] (start) -- node[above right] {Task Parallel} (scale);
		\draw[->] (pattern) -- node[left] {Yes} (openmp);
		\draw[->] (scale) -- node[above left] {Single Node} (cpp);
		\draw[->] (scale) -- node[above right] {Multi-node} (mpi);
	\end{tikzpicture}

	\vspace{1em}
	\textbf{Detailed Comparison}:
	\begin{table}[h]
		\centering
		\tiny
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Criteria}    & \textbf{OpenMP} & \textbf{C++ Thread} & \textbf{MPI} \\
			\hline
			Learning Curve       & Easy            & Moderate            & Hard         \\
			Development Time     & Fast            & Medium              & Slow         \\
			Performance Control  & Low             & High                & High         \\
			Debugging Complexity & Low             & Medium              & High         \\
			Memory Model         & Shared          & Shared              & Distributed  \\
			Scalability          & 1-64 cores      & 1-32 cores          & 1000s cores  \\
			\hline
			\textbf{Best For}    & Loops           & Complex Logic       & HPC Clusters \\
			\hline
		\end{tabular}
	\end{table}
\end{frame}

\subsection{Comprehensive Example}
\begin{frame}[fragile]{\emoji{dart} Monte Carlo π Calculation: All Frameworks}
	\textbf{Problem}: Estimate π using random point sampling

	\begin{columns}
		\begin{column}{0.3\textwidth}
			\textbf{OpenMP Version}
			\begin{minted}{cpp}
#include <omp.h>
#include <random>

double monte_carlo_openmp(long samples) {
    long count = 0;

    #pragma omp parallel reduction(+:count)
    {
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_real_distribution<> dis(0.0, 1.0);

        #pragma omp for
        for(long i = 0; i < samples; i++) {
            double x = dis(gen);
            double y = dis(gen);
            if(x*x + y*y <= 1.0) {
                count++;
            }
        }
    }

    return 4.0 * count / samples;
}
			\end{minted}
		\end{column}
		\begin{column}{0.35\textwidth}
			\textbf{C++ Thread Version}
			\begin{minted}{cpp}
#include <thread>
#include <vector>
#include <atomic>

std::atomic<long> global_count(0);

void worker(long samples) {
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<> dis(0.0, 1.0);

    long local_count = 0;
    for(long i = 0; i < samples; i++) {
        double x = dis(gen);
        double y = dis(gen);
        if(x*x + y*y <= 1.0) {
            local_count++;
        }
    }

    global_count += local_count;
}

double monte_carlo_cpp(long samples) {
    const int num_threads = std::thread::hardware_concurrency();
    std::vector<std::thread> threads;

    long samples_per_thread = samples / num_threads;

    for(int i = 0; i < num_threads; i++) {
        threads.emplace_back(worker, samples_per_thread);
    }

    for(auto& t : threads) {
        t.join();
    }

    return 4.0 * global_count / samples;
}
			\end{minted}
		\end{column}
		\begin{column}{0.35\textwidth}
			\textbf{MPI Version}
			\begin{minted}{cpp}
#include <mpi.h>

double monte_carlo_mpi(long samples) {
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    long local_samples = samples / size;
    long local_count = 0;

    std::random_device rd;
    std::mt19937 gen(rd() + rank);
    std::uniform_real_distribution<> dis(0.0, 1.0);

    for(long i = 0; i < local_samples; i++) {
        double x = dis(gen);
        double y = dis(gen);
        if(x*x + y*y <= 1.0) {
            local_count++;
        }
    }

    long global_count;
    MPI_Reduce(&local_count, &global_count, 1,
               MPI_LONG, MPI_SUM, 0, MPI_COMM_WORLD);

    if(rank == 0) {
        return 4.0 * global_count / samples;
    }
    return 0.0;
}
			\end{minted}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}[fragile]{\emoji{bar-chart} Performance Analysis}
	\textbf{Benchmark Results} (1 billion samples):

	\begin{table}[h]
		\centering
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			\textbf{Framework} & \textbf{Time (s)} & \textbf{Speedup} & \textbf{Accuracy} & \textbf{LOC} \\
			\hline
			Sequential         & 12.5              & 1.0×             & π ≈ 3.141592      & 15           \\
			OpenMP             & 1.8               & 6.9×             & π ≈ 3.141591      & 20           \\
			C++ Thread         & 1.9               & 6.6×             & π ≈ 3.141593      & 35           \\
			MPI (8 nodes)      & 0.3               & 41.7×            & π ≈ 3.141590      & 40           \\
			\hline
		\end{tabular}
	\end{table}

	\vspace{1em}
	\textbf{Trade-offs Analysis}:
	\begin{itemize}
		\item \textbf{OpenMP}: Best effort/performance ratio for shared memory
		\item \textbf{C++ Thread}: Maximum control, good for complex algorithms
		\item \textbf{MPI}: Unmatched scalability for distributed computing
	\end{itemize}

	\vspace{0.5em}
	\textbf{Development Productivity}:
	\begin{tikzpicture}
		\draw[fill=green!30] (0,0) rectangle (4,0.3);
		\draw[fill=yellow!30] (0,0.4) rectangle (2.5,0.7);
		\draw[fill=red!30] (0,0.8) rectangle (1.5,1.1);

		\node[right] at (4.1,0.15) {OpenMP (Fast prototyping)};
		\node[right] at (2.6,0.55) {C++ Thread (Balanced)};
		\node[right] at (1.6,0.95) {MPI (Complex setup)};
	\end{tikzpicture}
\end{frame}

\subsection{Advanced Topics Preview}
\begin{frame}[fragile]{\emoji{telescope} Beyond the Basics: Advanced Concurrency}
	\textbf{Topics for Further Exploration}:

	\begin{columns}
		\begin{column}{0.5\textwidth}
			\textbf{Asynchronous Programming}
			\begin{minted}{cpp}
#include <future>

auto future = std::async(std::launch::async,
    []() {
        return expensive_computation();
    });

// Do other work...
auto result = future.get();  // Wait for result
			\end{minted}

			\textbf{Atomic Operations}
			\begin{minted}{cpp}
#include <atomic>

std::atomic<int> counter{0};

void increment() {
    counter.fetch_add(1, std::memory_order_relaxed);
}
			\end{minted}
		\end{column}
		\begin{column}{0.5\textwidth}
			\textbf{Thread Pools}
			\begin{minted}{cpp}
class ThreadPool {
    std::vector<std::thread> workers;
    std::queue<std::function<void()>> tasks;
    std::mutex queue_mutex;
    std::condition_variable condition;

public:
    template<class F>
    void enqueue(F&& f) {
        {
            std::lock_guard<std::mutex> lock(queue_mutex);
            tasks.emplace(std::forward<F>(f));
        }
        condition.notify_one();
    }
};
			\end{minted}
		\end{column}
	\end{columns}

	\vspace{1em}
	\textbf{Learning Path}:
	\begin{enumerate}
		\item Master the basics: \texttt{thread}, \texttt{mutex}, \texttt{condition\_variable}
		\item Explore \texttt{std::async} and \texttt{std::future}
		\item Study atomic operations and memory models
		\item Implement lock-free data structures
		\item Build thread pools and work-stealing algorithms
	\end{enumerate}
\end{frame}
