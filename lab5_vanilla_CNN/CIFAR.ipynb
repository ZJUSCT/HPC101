{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import necessities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Define the parameters here\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.c1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)  # Input(3, 32, 32) Output(6, 28, 28)\n",
    "        self.s2 = nn.MaxPool2d(2, 2)  # Output (6, 14, 14)\n",
    "        self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)  # Input(6, 14, 14) Output(16, 10, 10)\n",
    "        self.s4 = nn.MaxPool2d(2, 2)  # Output (16, 5, 5)\n",
    "        self.c5 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        self.out = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.c1(x))\n",
    "        x = self.s2(x)\n",
    "        x = self.relu(self.c3(x))\n",
    "        x = self.s4(x)\n",
    "        x = self.relu(self.c5(x.view(x.size()[0], -1)))\n",
    "        x = self.relu(self.f6(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = LeNet().to(device)\n",
    "# 使用随机生成的样例测试模型\n",
    "# 四个维度分别为[batch_size, channels, height, width]\n",
    "t1 = torch.rand([10, 3, 32, 32])\n",
    "model(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set optimizer and loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data for training\n",
    "和MNIST类似，加载数据集有两种方式torch.utils.data.DataLoader\n",
    "- 使用Dataset与DataLoader加载\n",
    "- 使用官方提供的函数加载\n",
    "\n",
    "其中前者由于torchvision中提供了函数`torchvision.datasets.CIFAR10`，不用手写继承 Dataset 类处理函数，因此更为方便"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用torchvision提供的函数\n",
    "\n",
    "# 归一化，after = (before - mean) / std\n",
    "# 前三个0.5代表每个通道的mean 后三个代表每个通道的std\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./src/', train=True,\n",
    "                                         download=False, transform=transform)\n",
    "train_loader = Data.DataLoader(train_set, batch_size=36,\n",
    "                               shuffle=False, num_workers=0)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./src/', train=False,\n",
    "                                        download=False, transform=transform)\n",
    "test_loader = Data.DataLoader(test_set, batch_size=5000,\n",
    "                              shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        _dict = pickle.load(fo, encoding='bytes')\n",
    "    return _dict\n",
    "\n",
    "\n",
    "a = unpickle(\"./src/cifar-10-batches-py/data_batch_1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "以下函数可显示读取到的数据，可用于检测数据是否正确读取\n",
    "\n",
    "此外需要注意的是，DataLoader类型的数据需要转化为迭代器后取出\n",
    "\n",
    "`np.transpose`用于调整图片的维度顺序，原本为[3, 32, 32]，调整后为[32, 32, 3]以便输出"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 展示图片\n",
    "def img_show(data):\n",
    "    data = data / 2 + 0.5\n",
    "    plt.imshow(np.transpose(data.numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "img_data = iter(train_loader)\n",
    "img_data, _ = next(img_data)\n",
    "img_show(img_data[1])\n",
    "data = img_data[1] / 2 + 0.5\n",
    "np.transpose(data.numpy(), (1, 2, 0)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    sum_loss = .0\n",
    "    for i, (in_data, out_data) in enumerate(train_loader):\n",
    "        in_data = in_data.to(device)\n",
    "        out_data = out_data.to(device)\n",
    "        pred = model(in_data)\n",
    "        loss = criterion(pred, out_data)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss\n",
    "    print(\"epoch \", epoch, \"  Loss: \", np.float32(sum_loss.data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (in_data, out_data) in enumerate(test_loader):\n",
    "        outputs = model(in_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += out_data.shape[0]\n",
    "        correct += (predicted == out_data).sum()\n",
    "print(\"Correct rate: \", np.float32(100 * correct / total), \"%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 尝试使用`pytorch lightning`\n",
    "For more tutorials, visit [here](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html)\n",
    "\n",
    "You can simply turn PyTorch into Lightning by just reading [this](https://pytorch-lightning.readthedocs.io/en/latest/starter/converting.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | relu    | ReLU      | 0     \n",
      "1 | sigmoid | Sigmoid   | 0     \n",
      "2 | c1      | Conv2d    | 456   \n",
      "3 | s2      | MaxPool2d | 0     \n",
      "4 | c3      | Conv2d    | 2.4 K \n",
      "5 | s4      | MaxPool2d | 0     \n",
      "6 | c5      | Linear    | 48.1 K\n",
      "7 | f6      | Linear    | 10.2 K\n",
      "8 | out     | Linear    | 850   \n",
      "--------------------------------------\n",
      "62.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.0 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3b46f2018e54ee881f10423ed22a4c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76402437f7a0412692cd7c113d1239fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e94c397a0e2466394475b1e109e9949"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51019b8a253c46918aebf900cccb6753"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec359585a4314cb18d1dc94d678c8c32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "547442c97826480187e70efaf27f3b9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55fd3532ea374c9396cc70a0f51251f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e845d68b9334ed08f0655d069449443"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72cae5a69dbe4b92881de5e5e08bcc59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac23f9e7b6a34a98ba5521d22def8cbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b99736125d33477099f8bb00bc55b4db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2639e9eda7894608ac4f1522d0ac53d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b108a0b5726491fa1e74e29d69205b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1252aea326164eaaa7283f049675265e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0df3ceb3737648c58ba091ddddc8819d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f5d8ab63e0746d99aec22fe743f487f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5c59e76daaf41909b8a80e6f3143296"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "class LeNet_pl(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LeNet_pl, self).__init__()\n",
    "        # Define the parameters here\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.c1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)  # Input(3, 32, 32) Output(6, 28, 28)\n",
    "        self.s2 = nn.MaxPool2d(2, 2)  # Output (6, 14, 14)\n",
    "        self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)  # Input(6, 14, 14) Output(16, 10, 10)\n",
    "        self.s4 = nn.MaxPool2d(2, 2)  # Output (16, 5, 5)\n",
    "        self.c5 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        self.out = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.c1(x))\n",
    "        x = self.s2(x)\n",
    "        x = self.relu(self.c3(x))\n",
    "        x = self.s4(x)\n",
    "        x = self.relu(self.c5(x.view(x.size()[0], -1)))\n",
    "        x = self.relu(self.f6(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        _optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        return _optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        _x, _y = train_batch\n",
    "        _pred = self(_x)\n",
    "        _loss = F.cross_entropy(_pred, _y)\n",
    "        # _loss = F.mse_loss(_pred, _y)\n",
    "        self.log('train_loss', _loss)\n",
    "        return _loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        _x, _y = val_batch\n",
    "        _pred = self(_x)\n",
    "        _loss = F.cross_entropy(_pred, _y)\n",
    "        # _loss = F.mse_loss(_pred, _y)\n",
    "        acc = accuracy(_pred, _y)\n",
    "        self.log('acc', acc, prog_bar=True)\n",
    "        self.log('val_loss', _loss)\n",
    "\n",
    "\n",
    "# Set up for the dataset and dataloader\n",
    "trans = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./src/', train=True,\n",
    "                                         download=False, transform=trans)\n",
    "train_loader = Data.DataLoader(train_set, batch_size=36,\n",
    "                               shuffle=True, num_workers=0)\n",
    "\n",
    "val_set = torchvision.datasets.CIFAR10(root='./src/', train=False,\n",
    "                                       download=False, transform=trans)\n",
    "val_loader = Data.DataLoader(val_set, batch_size=5000,\n",
    "                             shuffle=False, num_workers=0)\n",
    "\n",
    "# model\n",
    "model = LeNet_pl()\n",
    "# using tensorboard to visualize in pytorch lightning\n",
    "# execute `tensorboard --logdir ./lightning_logs` and visit through the browser\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "logger = TensorBoardLogger('lightning_logs/', name='LeNet-5')\n",
    "# Remember to set your own training parameters for the trainer\n",
    "# You can get to know more about the trainer at https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.trainer.trainer.html#module-pytorch_lightning.trainer.trainer\n",
    "trainer = pl.Trainer(max_epochs=15, logger=logger)\n",
    "# training\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d9814caa",
   "language": "python",
   "display_name": "PyCharm (Intro-Lab5-CNN)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}